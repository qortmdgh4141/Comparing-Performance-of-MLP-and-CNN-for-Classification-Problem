{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPQMzzPfIUWIdh39ApqZnsr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qortmdgh4141/Comparing-Performance-of-MLP-and-CNN-for-Classification-Problem/blob/main/MLP_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. 패키지 설정**"
      ],
      "metadata": {
        "id": "g4PrYBjjfO7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import initializers\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Dropout, Input, Conv2D, MaxPooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ul8pOMMY-rqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. 데이터 준비**"
      ],
      "metadata": {
        "id": "DfJ8BCbYfvfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습용, 검증용, 테스트용으로 분리하여 MNIST 데이터 셋트 로딩\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=42)\n",
        "\n",
        "# 학습용 & 검즘용 & 테스트용 데이터의 차원\n",
        "print(f\"학습용 데이터의 차원 : 입력 데이터 {x_train.shape} / 라벨 데이터 / {y_train.shape}\") \n",
        "print(f\"검증용 데이터의 차원 : 입력 데이터 {x_val.shape} / 라벨 데이터 / {y_val.shape}\")\n",
        "print(f\"테스트용 데이터의 차원 : 입력 데이터 {x_test.shape} / 라벨 데이터 / {y_test.shape}\")"
      ],
      "metadata": {
        "id": "g8NrsIkNfMX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10개의 이미지와 목표 변수를 그래프로 출력\n",
        "plt.figure(figsize=(12, 2))\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(x_train[i], cmap='gray')\n",
        "    plt.title(str(y_train[i]))\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "odGf6UW8nkbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. 탐색적 데이터 분석**"
      ],
      "metadata": {
        "id": "oITHFK4RhmwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 데이터의 차원 변환 : 3차원(이미지 수, 28, 28) -> 2차원 (이미지 수, 784)\n",
        "x_train_reshaped = x_train.reshape(x_train.shape[0], 784)\n",
        "\n",
        "# 데이터 프레임으로 변형하여 널 값의 빈도 확인\n",
        "x_train_df = pd.DataFrame(x_train_reshaped)\n",
        "total_null_count = x_train_df.isnull().sum().sum()\n",
        "print(f\"널값의 개수 : {total_null_count}개\")"
      ],
      "metadata": {
        "id": "S-QQ-auL5y2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 열별로 픽셀의 강도 분석\n",
        "x_train_df.describe()"
      ],
      "metadata": {
        "id": "ksYAbMsq74Ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 목표변수의 라벨별 빈도 계산 후 데이터 프레임으로 변환\n",
        "y_cnt = pd.DataFrame(y_train).value_counts()\n",
        "df = pd.DataFrame(y_cnt, columns=['Count'])\n",
        "\n",
        "# 인덱스 리셋 및 문자열로 변환\n",
        "df.reset_index(inplace=True)  \n",
        "df['Label'] = df[0].astype(str)\n",
        "\n",
        "# 컬러맵 설정 및 바차트 생성\n",
        "cmap = plt.cm.Set3 \n",
        "fig, ax = plt.subplots(figsize=(12, 3)) \n",
        "bars = ax.bar(df['Label'], df['Count'], color=cmap(np.arange(len(df))))\n",
        "\n",
        "# 바 위에 라벨 갯수 출력\n",
        "for i, count in enumerate(df['Count']):\n",
        "    ax.text(i, count + 100, str(count), ha='center', fontsize=7)\n",
        "\n",
        "# 그래프 레이블과 제목 설정 및  y축 범위 늘리기 (현재 최댓값의 110%로 범위 지정)\n",
        "ax.set_xlabel('Label')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title('Label Counts')\n",
        "ax.set_ylim(0, df['Count'].max() * 1.1)\n",
        "\n",
        "plt.show() # 그래프 출력"
      ],
      "metadata": {
        "id": "9IFrwZNhouSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. 피처 스케일링**"
      ],
      "metadata": {
        "id": "8ceb66rNuKDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력데이터는 모두 0~255 사이 값이기 때문에 각각 255로 나누어 0~1로 정규화\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_val = x_val.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "metadata": {
        "id": "duDnjfGcuD4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. 원-핫 인코딩**"
      ],
      "metadata": {
        "id": "QY6h8uzpxn8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라벨 데이터의 원-핫 인코딩\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_val = np_utils.to_categorical(y_val)\n",
        "y_test = np_utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "zHzGXrDrxiYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. MLP 모델 기반 학습 & 테스트**"
      ],
      "metadata": {
        "id": "S5FzERhrveb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1. 완전연결 계층 (Dense Layer)\n",
        "    - 노드 수: 512 or 10\n",
        "    - 완전연결 계층은 모든 입력과 출력을 연결하는 전통적인 신경망 계층\n",
        "    - 추상적인 특징을 학습하고, 다양한 클래스에 대한 확률 분포를 출력하는 역할을 수행\n",
        "\n",
        "2. 드롭아웃(Dropout) 층\n",
        "    - 신경망의 학습 과정에서 과적합을 줄이기 위해 사용되는 정규화 기법인 드롭아웃(Dropout) 층을 추가\n",
        "    - 드롭아웃은 학습 과정 중에 신경망의 일부 유닛(neuron)을 임의로 선택하여 비활성화시킴으로써,\n",
        "      모델이 특정 유닛에 과도하게 의존하는 것을 방지하거 일반화 능력을 향상\n",
        "\n",
        "3. 은닉층의 활성화 함수 :  Relu\n",
        "   - 입력값이 0보다 작을 경우는 0으로 출력하고, 0보다 큰 경우는 그대로 출력하는 비선형 함수인 Relu 함수로 설정\n",
        "   - ReLU 활성화 함수를 사용할 때, 가중치 초기화에 따른 그래디언트 소실 문제를 완화하기 위해 은닉층의 가중치는 He 초깃값을 사용\n",
        "\n",
        "4. 출력층의 활성화 함수 :  Softmax\n",
        "   - 주로 다중 클래스 분류 문제에서 출력층에서 사용되는 활성화 함수인  Softmax로 설정\n",
        "   - Softmax 함수는 입력받은 값을 정규화하여 각 클래스에 속할 확률을 계산하며, 모든 클래스에 대한 확률의 합은 1\n",
        "\n",
        "5. 최적화 알고리즘 : Adam\n",
        "   - Momentum과 RMSProp의 장점을 결합한 최적화 알고리즘인 Adam(Adaptive Moment Estimation)을 사용\n",
        "   - Momentum은 : 기울기의 방향을 고려하여 학습 속도를 조절 \n",
        "   - RMSProp : 기울기 크기를 고려하여 학습 속도를 조절\n",
        "\n",
        "6. 손실 함수 : Cross-Entropy Loss Function\n",
        "   - 출력층에서 Softmax 함수를 사용할 경우, 손실 함수로는 주로 크로스 엔트로피 손실 함수를 사용\n",
        "   - 크로스 엔트로피 손실 함수(Cross-Entropy Loss Function)는 실제 타깃 값에 해당하는 클래스에 대해서만 오차를 계산하며, \n",
        "     오차를 최소화하는 방향으로 학습이 진행\n",
        "\n",
        "7. 정확도 평가 지표 : Accuracy\n",
        "   - 분류 모델의 성능을 평가하는 지표 중 하나인 Accuracy를 사용\n",
        "   - 예측한 클래스가 실제 타깃 클래스와 일치하는 경우를 정확한 분류로 간주하고, 이를 전체 샘플 수로 나누어 정확도를 계산\n",
        "\n",
        "8. 배치 사이즈 / 학습 반복 횟수 / 학습률 : 128 / 100 / 0.001\n",
        "\"\"\"\n",
        "# 모형 구조  \n",
        "mlp_model = Sequential()\n",
        "mlp_model.add(Flatten(input_shape=(28, 28)))\n",
        "mlp_model.add(Dropout(0.5))\n",
        "mlp_model.add(Dense(512, activation='relu', kernel_initializer=initializers.HeNormal()))\n",
        "mlp_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "mlp_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy']) \n",
        "\n",
        "mlp_model.summary() # 모형 구조 출력 "
      ],
      "metadata": {
        "id": "X8GSqi2KvNGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "results_mlp = mlp_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, batch_size=128)"
      ],
      "metadata": {
        "id": "fLBg6irq1Ob5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습된 모형 테스트 \n",
        "mlp_score = mlp_model.evaluate(x_test, y_test)\n",
        "mlp_accuracy = round(mlp_score[1]*100, 2)\n",
        "print(f\"MLP 모델 기반 테스트 데이터의 손실함수 값 : {round(mlp_score[0], 2)}\")\n",
        "print(f\"MLP 모델 기반 테스트 데이터의 정확도      : {mlp_accuracy}%\")"
      ],
      "metadata": {
        "id": "zL_ug3f6-w05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습된 모형으로 테스트 데이터를 예측\n",
        "mlp_y_pred = mlp_model.predict(x_test)\n",
        "\n",
        "# 예측 값과 실제 값의 라벨\n",
        "mlp_y_pred_class = np.argmax(mlp_y_pred, axis=1)\n",
        "y_test_class = np.argmax(y_test, axis=1)\n",
        "\n",
        "# 교차표 : 실제 값 대비 예측 값 (주대각원소의 값이 정확하게 분류된 빈도, 그 외는 오분류 빈도)\n",
        "mlp_crosstab = pd.crosstab(y_test_class,mlp_y_pred_class)\n",
        "mlp_crosstab"
      ],
      "metadata": {
        "id": "o42dszkJBMwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. CNN 모델 기반 학습 & 테스트**"
      ],
      "metadata": {
        "id": "pq7ogflSEhC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1. 합성곱 층 (Convolutional Layer)\n",
        "    - 필터 개수: 32 or 64, 커널 크기 : (3, 3)\n",
        "    - 합성곱 층은 입력 데이터에 대해 필터(커널)를 이용하여 지역적인 특징을 추출 특성 맵(Feature Map)을 생성\n",
        "\n",
        "2. 풀링 층 (Pooling Layer) \n",
        "    - 최대 풀링 크기: (2, 2)\n",
        "    - 풀링 층은 공간적인 불변성을 제공하고, 특성 맵의 크기를 줄여 계산량을 감소시키고, 추상화된 특징을 더 강조함\n",
        "\n",
        "3. 완전연결 계층 (Dense Layer)\n",
        "    - 노드 수: 512 or 10\n",
        "    - 완전연결 계층은 모든 입력과 출력을 연결하는 전통적인 신경망 계층\n",
        "    - 추상적인 특징을 학습하고, 다양한 클래스에 대한 확률 분포를 출력하는 역할을 수행\n",
        "\n",
        "4. 드롭아웃(Dropout) 층\n",
        "    - 신경망의 학습 과정에서 과적합을 줄이기 위해 사용되는 정규화 기법인 드롭아웃(Dropout) 층을 추가\n",
        "    - 드롭아웃은 학습 과정 중에 신경망의 일부 유닛(neuron)을 임의로 선택하여 비활성화시킴으로써,\n",
        "      모델이 특정 유닛에 과도하게 의존하는 것을 방지하거 일반화 능력을 향상\n",
        "\n",
        "5. 은닉층의 활성화 함수 :  Relu\n",
        "   - 입력값이 0보다 작을 경우는 0으로 출력하고, 0보다 큰 경우는 그대로 출력하는 비선형 함수인 Relu 함수로 설정\n",
        "   - ReLU 활성화 함수를 사용할 때, 가중치 초기화에 따른 그래디언트 소실 문제를 완화하기 위해 은닉층의 가중치는 He 초깃값을 사용\n",
        "\n",
        "6. 출력층의 활성화 함수 :  Softmax\n",
        "   - 주로 다중 클래스 분류 문제에서 출력층에서 사용되는 활성화 함수인  Softmax로 설정\n",
        "   - Softmax 함수는 입력받은 값을 정규화하여 각 클래스에 속할 확률을 계산하며, 모든 클래스에 대한 확률의 합은 1\n",
        "\n",
        "7. 최적화 알고리즘 : Adam\n",
        "   - Momentum과 RMSProp의 장점을 결합한 최적화 알고리즘인 Adam(Adaptive Moment Estimation)을 사용\n",
        "   - Momentum은 : 기울기의 방향을 고려하여 학습 속도를 조절 \n",
        "   - RMSProp : 기울기 크기를 고려하여 학습 속도를 조절\n",
        "\n",
        "8. 손실 함수 : Cross-Entropy Loss Function\n",
        "   - 출력층에서 Softmax 함수를 사용할 경우, 손실 함수로는 주로 크로스 엔트로피 손실 함수를 사용\n",
        "   - 크로스 엔트로피 손실 함수(Cross-Entropy Loss Function)는 실제 타깃 값에 해당하는 클래스에 대해서만 오차를 계산하며, \n",
        "     오차를 최소화하는 방향으로 학습이 진행\n",
        "\n",
        "9. 정확도 평가 지표 : Accuracy\n",
        "   - 분류 모델의 성능을 평가하는 지표 중 하나인 Accuracy를 사용\n",
        "   - 예측한 클래스가 실제 타깃 클래스와 일치하는 경우를 정확한 분류로 간주하고, 이를 전체 샘플 수로 나누어 정확도를 계산\n",
        "\n",
        "10. 배치 사이즈 / 학습 반복 횟수 / 학습률 : 128 / 100 / 0.001\n",
        "\"\"\"\n",
        "\n",
        "# 모형 구조\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), kernel_initializer=initializers.HeNormal()))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "cnn_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), kernel_initializer=initializers.HeNormal()))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(512, activation='relu', kernel_initializer=initializers.HeNormal()))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "cnn_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "cnn_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
        "\n",
        "cnn_model.summary() # 모형 구조 출력 "
      ],
      "metadata": {
        "id": "aCOlvHp3EmNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "results_cnn = cnn_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, batch_size=128)"
      ],
      "metadata": {
        "id": "Vi4-A-U3MBec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습된 모형 테스트 \n",
        "cnn_score = cnn_model.evaluate(x_test, y_test)\n",
        "cnn_accuracy = round(cnn_score[1]*100, 2)\n",
        "print(f\"CNN 모델 기반 테스트 데이터의 손실함수 값 : {round(cnn_score[0], 2)}\")\n",
        "print(f\"CNN 모델 기반 테스트 데이터의 정확도      : {cnn_accuracy}%\")"
      ],
      "metadata": {
        "id": "ulwYPRVsM3Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습된 모형으로 테스트 데이터를 예측\n",
        "cnn_y_pred = cnn_model.predict(x_test)\n",
        "\n",
        "# 예측 값과 실제 값의 라벨\n",
        "cnn_y_pred_class = np.argmax(cnn_y_pred, axis=1)\n",
        "y_test_class = np.argmax(y_test, axis=1)\n",
        "\n",
        "# 교차표 : 실제 값 대비 예측 값 (주대각원소의 값이 정확하게 분류된 빈도, 그 외는 오분류 빈도)\n",
        "cnn_crosstab = pd.crosstab(y_test_class, cnn_y_pred_class)\n",
        "cnn_crosstab"
      ],
      "metadata": {
        "id": "WIxQV2AfM5-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. MLP vs CNN 모델 성능 비교**"
      ],
      "metadata": {
        "id": "np-_C_2oSFVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_and_accuracy(train_loss, val_loss, train_acc, val_acc, model_name):\n",
        "    epochs = range(1, len(train_loss) + 1)\n",
        "    \n",
        "    plt.figure(figsize=(12, 6))\n",
        "    \n",
        "    # Loss 그래프\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
        "    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "    plt.title(f'{model_name} Model - Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    \n",
        "    # Accuracy 그래프\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(epochs, train_acc, 'b', label='Training Accuracy')\n",
        "    plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "    plt.title(f'{model_name} Model - Training and Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "# MLP 모델 결과 그래프 출력\n",
        "plot_loss_and_accuracy(results_mlp.history['loss'], results_mlp.history['val_loss'],\n",
        "                       results_mlp.history['accuracy'], results_mlp.history['val_accuracy'], 'MLP')\n",
        "\n",
        "# CNN 모델 결과 그래프 출력\n",
        "plot_loss_and_accuracy(results_cnn.history['loss'], results_cnn.history['val_loss'],\n",
        "                       results_cnn.history['accuracy'], results_cnn.history['val_accuracy'], 'CNN')\n"
      ],
      "metadata": {
        "id": "A4WjISyxihQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradientbars(bars, cmap_list):\n",
        "    grad = np.atleast_2d(np.linspace(0, 1, 256)).T\n",
        "    ax = bars[0].axes\n",
        "    lim = ax.get_xlim() + ax.get_ylim()\n",
        "    ax.axis(lim)\n",
        "    max_width = max([bar.get_width() for bar in bars])\n",
        "    for i, bar in enumerate(bars):\n",
        "        bar.set_facecolor(\"none\")\n",
        "        x, y = bar.get_xy()\n",
        "        w, h = bar.get_width(), bar.get_height()\n",
        "        ax.imshow(grad, extent=[x, x + w, y, y + h], aspect=\"auto\", cmap=cmap_list[i])\n",
        "        plt.text(w + 0.7, y + h / 2.0 + 0.015, \"{}\".format(int(w)), fontsize=8, ha='left', va='center')\n",
        "\n",
        "# MLP 모델 및 CNN 모델의 오분류 빈도\n",
        "mlp_error_count = len(y_test_class) - np.sum(y_test_class == mlp_y_pred_class)\n",
        "cnn_error_count = len(y_test_class) - np.sum(y_test_class == cnn_y_pred_class)\n",
        "error_counts = [mlp_error_count, cnn_error_count]\n",
        "\n",
        "# 막대 그래프로 오분류 빈도 표현\n",
        "models = ['MLP', 'CNN']\n",
        "cmap_list = ['Reds', 'Blues']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 4))\n",
        "bars = ax.barh(models, error_counts, color='white', alpha=0.7)\n",
        "gradientbars(bars, cmap_list)\n",
        "\n",
        "ax.set_ylabel('Model', fontsize=12)\n",
        "ax.set_xlabel('Error Count', fontsize=12)\n",
        "ax.set_title('< Error Count Comparison between MLP and CNN >', fontsize=10)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oTC6FGFEmTJ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}